---
title: "Toy Example: Basic Text Extraction"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(knitr)
```

## Basic Text Extraction Concepts

This notebook introduces fundamental concepts of text extraction using simple examples.

## Load Packages and Functions

```{r load-packages}
library(dplyr)
library(stringr)
library(ggplot2)
library(jsonlite)

source("../R/utils.R")
source("../R/extractors.R")
source("../R/evaluation.R")
source("../R/gemini_extraction.R")
```

## Create Sample Data

```{r create-data}
sample_texts <- c(
 "John Smith works at Acme Corp as a Data Scientist. Email: john.smith@acme.com, phone: (555) 123-4567.",
 "Contact Sarah Johnson, Senior Developer at Tech Solutions Inc. Email: sarah.j@techsolutions.org, Phone: +1-555-987-6543.",
 "Dr. Michael Brown is Head of Research at Innovation Labs. Office: (555) 111-2222, email: mbrown@innovation.com.",
 "Alice Wong, Marketing Manager, can be reached at alice.wong@marketing.co or 555-333-4444.",
 "Professor David Lee (david.lee@university.edu) teaches at State University. Call: 555-555-5555."
)

tibble(
  ID = 1:length(sample_texts),
  Text = substr(sample_texts, 1, 60)
) %>% kable(caption = "Sample texts for extraction")
```

## Rule-Based Extraction

```{r regex-patterns}
patterns <- list(
  email = "[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}",
  phone = "\\+?1?[\\s-]?\\(?\\d{3}\\)?[\\s.-]?\\d{3}[\\s.-]?\\d{4}",
  name = "(?:Dr\\.|Prof\\.|Professor)?\\s*[A-Z][a-z]+\\s+[A-Z][a-z]+"
)

tibble(
  Pattern = names(patterns),
  Regex = sapply(patterns, function(x) substr(x, 1, 40))
) %>% kable(caption = "Regex patterns")
```

## Apply Rule-Based Extraction

```{r rule-based-extraction}
rule_results <- extract_with_rules(sample_texts, patterns)
rule_results %>% kable()
```

## Analyze Rule-Based Results

```{r analyze-rules}
rule_summary <- tibble(
  Text = 1:nrow(rule_results),
  Emails = sapply(rule_results$email, length),
  Phones = sapply(rule_results$phone, length),
  Names = sapply(rule_results$name, length)
)

rule_summary %>% kable(caption = "Extraction counts per text")
```

## LLM-Based Extraction

```{r llm-extraction}
extraction_prompt_template <- '
Extract from this text and return as JSON:
- name, email, phone, company, job_title

Text: %s

Return ONLY valid JSON with empty string "" for missing fields.
'

llm_results <- list()

for (i in 1:length(sample_texts)) {
  prompt <- sprintf(extraction_prompt_template, sample_texts[i])

  response <- tryCatch({
    simple_gemini(prompt)
  }, error = function(e) NULL)

  if (!is.null(response)) {
    parsed <- tryCatch({
      jsonlite::fromJSON(response)
    }, error = function(e) NULL)

    if (!is.null(parsed)) {
      parsed$text_id <- i
      llm_results[[i]] <- parsed
    }
  }

  Sys.sleep(1)
}

llm_results_df <- dplyr::bind_rows(llm_results)
llm_results_df %>% kable(caption = "LLM extraction results")
```

## Compare Extraction Methods

```{r comparison}
tibble(
  Aspect = c(
    "Speed", "Cost", "Determinism", "Offline",
    "Pattern matching", "Context understanding", "Complex entities"
  ),
  `Rule-Based` = c(
    "Fast", "Free", "Yes", "Yes",
    "Strong", "None", "Cannot extract"
  ),
  `LLM-Based` = c(
    "Slow (API)", "Per-call cost", "No", "No",
    "Good", "Strong", "Can extract"
  )
) %>% kable(caption = "Method comparison")
```

## Define Ground Truth

```{r ground-truth}
ground_truth <- list(
  list(name="John Smith", email="john.smith@acme.com", phone="(555) 123-4567",
       company="Acme Corp", job_title="Data Scientist"),
  list(name="Sarah Johnson", email="sarah.j@techsolutions.org", phone="+1-555-987-6543",
       company="Tech Solutions Inc", job_title="Senior Developer"),
  list(name="Michael Brown", email="mbrown@innovation.com", phone="(555) 111-2222",
       company="Innovation Labs", job_title="Head of Research"),
  list(name="Alice Wong", email="alice.wong@marketing.co", phone="555-333-4444",
       company=NA, job_title="Marketing Manager"),
  list(name="David Lee", email="david.lee@university.edu", phone="555-555-5555",
       company="State University", job_title="Professor")
)

ground_truth_df <- dplyr::bind_rows(ground_truth)
ground_truth_df$text_id <- seq_len(nrow(ground_truth_df))

ground_truth_df %>% kable(caption = "Ground truth data")
```

## Evaluate Email Extraction

```{r eval-email}
rule_emails <- unlist(rule_results$email)
llm_emails <- llm_results_df$email[llm_results_df$email != ""]
true_emails <- ground_truth_df$email

rule_email_metrics <- calculate_metrics(list(rule_emails), list(true_emails))
llm_email_metrics <- calculate_metrics(list(llm_emails), list(true_emails))

tibble(
  Method = c("Rule-based", "LLM-based"),
  Precision = c(rule_email_metrics$precision, llm_email_metrics$precision),
  Recall = c(rule_email_metrics$recall, llm_email_metrics$recall),
  F1 = c(rule_email_metrics$f1, llm_email_metrics$f1)
) %>% kable(caption = "Email extraction metrics")
```

## Evaluate Complex Fields

```{r eval-complex}
llm_companies <- llm_results_df$company[llm_results_df$company != ""]
true_companies <- ground_truth_df$company[!is.na(ground_truth_df$company)]

llm_titles <- llm_results_df$job_title[llm_results_df$job_title != ""]
true_titles <- ground_truth_df$job_title

tibble(
  Field = c("Company", "Job Title"),
  `LLM Extracted` = c(length(llm_companies), length(llm_titles)),
  `Ground Truth` = c(length(true_companies), length(true_titles)),
  `Exact Matches` = c(
    sum(tolower(llm_companies) %in% tolower(true_companies)),
    sum(tolower(llm_titles) %in% tolower(true_titles))
  )
) %>% kable(caption = "Complex field extraction")
```

## Performance Visualization

```{r visualize}
comparison_data <- tibble(
  method = rep(c("Rule-Based", "LLM-Based"), each = 3),
  metric = rep(c("Precision", "Recall", "F1"), 2),
  value = c(
    rule_email_metrics$precision, rule_email_metrics$recall, rule_email_metrics$f1,
    llm_email_metrics$precision, llm_email_metrics$recall, llm_email_metrics$f1
  )
)

ggplot(comparison_data, aes(x = method, y = value, fill = metric)) +
  geom_col(position = "dodge") +
  scale_y_continuous(limits = c(0, 1), labels = scales::percent) +
  labs(
    title = "Email Extraction Performance",
    x = "Method", y = "Score", fill = "Metric"
  ) +
  theme_minimal()
```

## Key Takeaways

```{r takeaways}
tibble(
  Approach = c("Rule-Based", "LLM-Based", "Hybrid"),
  `Best For` = c(
    "Well-defined patterns (emails, phones, dates)",
    "Complex contextual information (companies, titles)",
    "Balance of speed, cost, and accuracy"
  ),
  Recommendation = c(
    "Use for structured, standardized fields",
    "Use for semantic understanding tasks",
    "Combine both methods in production"
  )
) %>% kable()
```

## Next Steps

1. Understand basic extraction concepts
2. Compare rule-based vs. LLM extraction
3. Learn error handling in `0030_error_handling_basics.Rmd`
4. Apply to real Fusarium research data
