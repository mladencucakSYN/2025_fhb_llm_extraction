---
title: "Getting Started with LLM Text Extraction"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(dplyr)
library(stringr)
library(ggplot2)

# Source our custom functions
source("../R/utils.R")
source("../R/extractors.R")
source("../R/evaluation.R")
```

# LLM-Based Text Extraction

This notebook demonstrates basic text extraction techniques using different approaches.

## Load Sample Data

```{r load-data}
# Create sample text data
sample_texts <- c(
  "John Smith works at Acme Corp as a Data Scientist. He can be reached at john.smith@acme.com or (555) 123-4567.",
  "Contact Sarah Johnson, Senior Developer at Tech Solutions Inc. Email: sarah.j@techsolutions.org, Phone: +1-555-987-6543.",
  "Dr. Michael Brown is the Head of Research at Innovation Labs. His office number is (555) 111-2222."
)

print("Sample texts loaded:")
sample_texts
```

## Rule-Based Extraction

Let's start with simple rule-based extraction using regex patterns:

```{r rule-based}
# Define extraction patterns
patterns <- list(
  emails = "[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}",
  phones = "\\(?\\d{3}\\)?[\\s.-]?\\d{3}[\\s.-]?\\d{4}",
  names = "(?:Dr\\.|Mr\\.|Ms\\.|Mrs\\.)?\\s*[A-Z][a-z]+\\s+[A-Z][a-z]+"
)

# Extract using rules
rule_results <- extract_with_rules(sample_texts, patterns)
print("Rule-based extraction results:")
rule_results
```

## LLM-Based Extraction (TODO)

```{r llm-extraction}
# TODO: Students should implement these functions

# Example prompt for structured extraction
extraction_prompt <- "
Extract the following information from the text:
- Name
- Company
- Job Title
- Email
- Phone

Return the results in JSON format.
"

# TODO: Uncomment and implement
# openai_results <- extract_with_openai(sample_texts, extraction_prompt)
# anthropic_results <- extract_with_anthropic(sample_texts, extraction_prompt)

print("TODO: Implement LLM extraction functions")
```

## Evaluation

```{r evaluation}
# Define ground truth for evaluation
ground_truth_emails <- list(
  c("john.smith@acme.com"),
  c("sarah.j@techsolutions.org"), 
  c()  # No email in third text
)

# Calculate metrics for rule-based extraction
email_metrics <- calculate_metrics(rule_results$emails, ground_truth_emails)
print("Email extraction metrics:")
print(email_metrics)
```

## Visualization

```{r visualization}
# Create sample comparison data
comparison_data <- tibble(
  method = c("Rule-based", "OpenAI GPT", "Anthropic Claude"),
  precision = c(0.85, 0.92, 0.89),
  recall = c(0.78, 0.88, 0.91),
  f1 = c(0.81, 0.90, 0.90)
)

# Plot performance comparison
plot_performance(comparison_data)
```

## Next Steps

1. Implement the LLM extraction functions in `R/extractors.R`
2. Add your own API keys to a `.env` file
3. Test with your own datasets
4. Experiment with different prompts and models
5. Compare performance across different approaches

## Exercises for Students

1. **Implement OpenAI Integration**: Complete the `extract_with_openai()` function
2. **Implement Anthropic Integration**: Complete the `extract_with_anthropic()` function  
3. **Create Custom Patterns**: Add new regex patterns for extracting dates, addresses, or other entities
4. **Expand Evaluation**: Add more comprehensive evaluation metrics
5. **Try Different Prompts**: Experiment with various prompt engineering techniques